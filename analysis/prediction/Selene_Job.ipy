from custom_tools import print_md

# This class is used to send job to the cluster from the jupyter notebook
# Please see the notebook cluster_job_tutorial.ipynb for a detailed example
# 
# For this class to work you need to have the git repository in your home folder on the cluster
#
# → creating a class object will create a directory holding everything related to the job in the local ssh_remote_jobs/ folder
# → calling the run() function of the object will:
#     - scp the directory to the cluster ssh_remote_jobs/ folder
#     - setup a working environment to launch the job
#     - bsub the job
# → calling the get_results() function will:
#     - print an error if the job is not done or the folder was not found
#     - scp the files metrics.pkl and job_output.txt from the cluster to the local computer
class Selene_Job:
    def __init__(self, job_id, cluster_username, load_from_id = False):
        self.job_id = job_id
        self.local_job_directory_path = 'ssh_remote_jobs/job_' + str(job_id)
        self.selene_ssh_remote_jobs_path = cluster_username + '@selene.mskcc.org:/home/' + cluster_username + '/impact-annotator/analysis/prediction/ssh_remote_jobs'
        self.selene_job_directory_path = self.selene_ssh_remote_jobs_path + '/job_' + str(job_id)
        self.username = cluster_username

        file_found = ![ -e {self.local_job_directory_path} ] && echo "yes" || echo "no"
        file_found = file_found[0]

        if load_from_id:
            if file_found == "yes":
                print_md(self.get_job_md_string_('green') + '✅ job found and reloaded\n')
            else:
                print_md(self.get_job_md_string_('red') + '⚠️ does not exist yet\n')

        else:
            if file_found == "yes":
                print_md(self.get_job_md_string_('red') + '⚠️ job already exists, please remove it with `job.remove()` or use `load_from_id = True` when you create the job\n')
            else:
                print('➞ mkdir on local computer ' + self.local_job_directory_path)
                !mkdir {self.local_job_directory_path}
                print_md(self.get_job_md_string_('green') + '✅ created\n')


    def get_job_md_string_(self, color):
        return "<span style='color:" + color + "'>Job < " + str(self.job_id) + " >: </span>"


    def load_data(self, X, y):
        print('➞ save X.pkl & y.pkl in ' + self.local_job_directory_path)
        X.to_pickle(self.local_job_directory_path + '/X.pkl')
        y.to_pickle(self.local_job_directory_path + '/y.pkl')

        print_md(self.get_job_md_string_('green') + '✅ data loaded\n')


    def run(self, n_jobs = 1, short_job = True, memory = None):
        print('➞ scp ' + self.local_job_directory_path + ' to ' + self.selene_ssh_remote_jobs_path)

        !scp -r {self.local_job_directory_path} {self.selene_ssh_remote_jobs_path}

        setup_command = 'echo "➞ logged in $PWD on $HOSTNAME"; \
                  \
                  echo "➞ load ~/.bash_profile"; \
                  source ~/.bash_profile; \
                  export LSF_ENVDIR=/common/lsf/conf; export LSF_SERVERDIR=/common/lsf/9.1/linux2.6-glibc2.3-x86_64/etc; \
                  \
                  echo "➞ work on impact-annotator_env python virtualenv"; \
                  workon impact-annotator_env; \
                  \
                  cd ~/impact-annotator/analysis/prediction/ssh_remote_jobs/job_' + str(self.job_id) + '; \
                  echo "➞ launch job in $PWD";'

        bsub_command = 'bsub -o job_output.txt'
        if short_job:
            bsub_command += ' -We 59'
        if n_jobs > 1:
            if memory:
                bsub_command += ' -n ' + str(n_jobs) + ' -R "span[ptile=5,mem=' + str(memory) + ']"'
            else:
                bsub_command += ' -n ' + str(n_jobs) + ' -R "span[ptile=5]"'

        bsub_command +=' "python script.py"'

        command = setup_command + bsub_command

        !ssh {self.username}@selene.mskcc.org '{command}'

        print('➞ bsub command used: $ ' + bsub_command)
        print_md(self.get_job_md_string_('green') + '✅ submitted\n')


    def get_results(self):        
        command = 'cd ~/impact-annotator/analysis/prediction/ssh_remote_jobs/job_' + str(self.job_id) + '; \
                   [ -e metrics.pkl ] && echo "yes" || echo "no"'
            
        file_found = !ssh {self.username}@selene.mskcc.org '{command}'
        file_found = file_found[0]

        if file_found == "yes":
            print_md(self.get_job_md_string_('green') + '✅ finished\n')
            print('➞ scp metrics.pkl & job_output.txt from ' + self.selene_job_directory_path + ' to ' + self.local_job_directory_path)
            ! scp -r {self.selene_job_directory_path}/metrics.pkl {self.local_job_directory_path}
            ! scp -r {self.selene_job_directory_path}/job_output.txt {self.local_job_directory_path}

            print('➞ load metrics.pkl in pandas dataframe self.metrics')
            self.metrics = pd.read_pickle(self.local_job_directory_path + '/metrics.pkl')

            print('➞ print main results')
            # mean metrics and 95% confidence interval on the metrics estimate (= 1.96 x standard_deviation)
            print_mean_metrics(self.metrics)

        else:
            print_md(self.get_job_md_string_('red') + '⚠️ does not exist, is not done yet or an error occured before the creation of `metrics.pkl`\n')


    def remove(self):
        print('➞ rm on local computer ' + self.local_job_directory_path + '')
        !rm -f -r {self.local_job_directory_path}

        print('➞ rm on cluster ' + self.selene_job_directory_path)
        command = 'rm -f -r ~/impact-annotator/analysis/prediction/ssh_remote_jobs/job_' + str(self.job_id)
        !ssh {self.username}@selene.mskcc.org '{command}'

        print_md(self.get_job_md_string_('green') + '✅ removed from local computer and cluster\n')


